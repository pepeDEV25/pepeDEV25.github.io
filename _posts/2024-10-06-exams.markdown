---
layout: post
title: "Parsing past Matura exams"
date: 2024-05-24
---

One of my study tricks for preparing for the Matura exam was to create a Matura parser. Given a list of recent Matura PDFs and a list of solution PDFs I had to somehow parse the results. There are two major problems here, every few years the process of creating PDFs changes and the PDFs themselves aren't made with any known tools, that may be decomposed.

# Part I: Parsing the tasks

We begin with the easier part first. We need to decompose the PDFs into different tasks. Each PDF has exactly 35 tasks (assignments). Unfortunately, we cannot just parse the text as there may be images or symbols that had to also be included. Therefore, we shall parse the tasks into their own PDFs. While this doesn't sound very tricky at first, it actually was. One of the problems is the lack of libraries that can successfully perform this. I have, unfortunately, not found any library that could execute all of the required functions, e.g. finding the position of where the tasks starts and cutting the PDF. Nevertheless, we may use a pypdf to read the PDF and find the coordinates of where the task is located, and employ pdfCropMargins to crop and export the task.

The easiest way of actually finding the positions $ \vec{p} $ of the task is to parse the positions of task numbering (i.e. 1., 2.a, 3.). Here, however, we must be careful since we may also have 1. as a part of the text. For example, the 1. (1st) person to cross the line is the winner. To exclude this, we can also check if the text object that we obtain from the parse has a length of less than 3. That is, the length of the number, which has at most 2 digits, plus the length of the char ".".

{% highlight python %}

coordinates = []
pages = []
for e in sl_json["blocks"]:
    if("lines" in e.keys()):
        for k in e["lines"]:
            for u in k["spans"]:
                text = str(u["text"])
                if(len(text) > 2 and ((text[0].isnumeric()) and (text[1] == '.' or text[2] == '.'))):
                    coordinates.append(u["origin"][1])
                    pages.append(text[0] +text[1]  if text[2] == '.' else text[0])

{% endhighlight %}

Let $̂p_i$ be the sequence of task positions. The length of the cropped text is $s = p_i - p_{i+1}$. Given both the position and the length, we may now convert this to a format the the crop library accepts.

{% highlight python %}
 for i in range(0, len(coordinates) - 1):
            crop(["-a4", "20", str(abs(coordinates[i + 1] - coordinates[i])), "20", str(coordinates[i]), "-o", folder + (str(pages[i]) + ".pdf"), folder + "page_bu.pdf"])

{% endhighlight %}

Note, that for this to truly work, we must also account for what happens when two tasks are on different pages. This can be done, by checking if $ p_i > p_{i+1}$, if that is the case for loop is readjusted such that the $s$ is calculated to the page height instead of $p_{i+1}$. 

The final result is a simple PDF a task. For practicality, I also named each PDF with their respective task number. This may allow for an easier database creation.

![Image]({{ site.baseurl }}/assets/posts/matura/29-1.png)

<i> Figure: Final PDF <i>

# Part II: Parsing the solutions

Parsing the solution PDF is (slightly) more tricky. By default, the results are in a table on the second or third page of the PDF. The table alignment did not really help with the overall parsing process. Instead I have noticed that when the PDF is parsed, we obtain the following

{% highlight python %}
d
OD
B
C
C
A
B
B
D
D
v
a
r
p123456789la
g
o
a
Nl
i
v
e
t
š
o
n
p
u
k
{% endhighlight %}

Whilst, this may seem fine at first, the answers take the value A,B,C or D, hence we see observe that there is a character "" takes place after each solution. It may seem that the character "" is in front of the solution at first, however, this is not the case, since the first large D has a number 0 in front and the letter v has  in front. Implying, that the symbol "" takes place after the letter. This prompts us to do a simple for loop to obtain and save the results

{% highlight python %}
    for e in document.elements.filter_by_page(3):
        try:
            if(e.text().find("") > 0) :
                if(e.text()[0].isupper() and not e.text()[0].isnumeric()): 
                    results.append(e.text()[0])
            f.write(e.text())
        except:
            pass
{% endhighlight %}

Hereby, I must also add that the letters appear in the following order ans. 28-36, ans. 19-28, ans. 10-19, ans. 1-10. At last, we pair the results with their respective index and output everything into a JSON file

{% highlight python %}
 res_map = dict()

    for i in range(0, 35):
        res_map[indexes[i]] = results[i]

    with open(folder + "res.json", "w") as file:
        json.dump({'name': matura.ime, 'poiskus': matura.poiskus, 'id_predmeta': matura.id_predmeta.name, 'leto': matura.leto, 'rok': matura.rok, 'pola': matura.pola,'res': res_map}, file)
{% endhighlight %}

The end result is the following json snippet

{% highlight json %}
{
    "name": "M171-411-1-3", 
    "poiskus": 1, "id_predmeta": 
    "FIZIKA", "leto": "17", 
    "rok": "1", 
    "pola": 3, 
    "res": {"28": "A", "29": "B", "30": "B", "31": "A", "32": "B", "33": "D", "34": "D", "35": "D", "19": "D", "20": "C", "21": "B", "22": "D", "23": "C", "24": "D", "25": "D", "26": "A", "27": "A", "10": "A", "11": "D", "12": "C", "13": "B", "14": "C", "15": "C", "16": "C", "17": "C", "18": "B", "1": "B", "2": "B", "3": "C", "4": "C", "5": "C", "6": "C", "7": "C", "8": "D", "9": "C"}
}
{% endhighlight %}

This combined with the PDFs can be used to create an app for learning. This has also been done. The code is available on my github.
